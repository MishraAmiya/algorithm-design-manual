---
layout: post
title: 2.6 Logarithms
---

* a logarithm is simply an inverse exponential function
* b^x=y => x=log(y) where the base of the logarithm is b
* exponential grows really fast, inverse exponential (log) grows slowly 
* logarithms arise in any process where things are repeatedly halved

## Applications

### binary search

* after each comparison half of the records can be discarded
* worst case log2(n) steps (base 2)

### binary tree height

* binary tree of height 1 => 2 leaf nodes
* binary tree of height 2 => 4 leaf nodes
* height h of a rooted binary tree with n leaf nodes: h = log2(n)
* trees with d children logd(n) (log base d)

### bits

* two bit patterns of length 1 (0,1)
* four bit patterns of length 2 (00, 01, 10, and 11)
* w bits representing n possibilities: 2^w=n ->  w=log2(n)

### multiplication

* loga(xy) = loga(x) + loga(y)
* loga(n^b) = b * loga(n)
* a^b using exp(x) = e^x and ln(x) = loge(x):
* a^b = exp(ln(a^b)) = exp(b ln a)

### fast exponentiation

* exactly compute a^n
* simplest: n-1 multiplications a * a ...
* n even a^n = (a^(n/2))^2
* n odd a^n = a(a^(n/2))^2
* we have halved the size of our exponent at the cost of two multiplications
* O(log n) multiplication will be enough

### summations

* Harmonic numbers: special case of arithmetic progression 
* H(n) = S(n, -1)
* the sum of the progression of simple reciprocals

![image](images/2.6-harmonic_numbers.jpg)
